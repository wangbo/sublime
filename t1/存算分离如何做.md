第一步可以把模块划分出来，做一个初步的思考就可以了
模拟出已有的场景思考
模拟出新的场景（弹性，adhoc）进行思考
哪些可以砍掉
不砍掉的如何改造

可以基于一个最简单的原型进行持续的改进

## 技术目标
弹性能够对齐业界水平

# why存算分离
## 场景视角
对Doris的能力做拓展

1 支持弹性，支持adhoc
	存储算需要能够解耦

2 保证现有的doris亚秒级olap引擎的定位
	需要保证本地性

## 最终设计概览

其实可以有两种技术选型
1 弄一个远程存储
2 强化doris数据拷贝的能力

# 要点设计

## BE通用

支持远程存储
	本地文件接口需要能够读远程数据

支持本地缓存
	缓存策略

be数据管理
	元数据
		放到普通远程存储(可以先假定用一个普通的远程存储) or 一个分布式数据库，比如tikv？

	data数据，放到远程存储上


## 导入
	事务机制
		不再需要publish和三副本的逻辑，但是依然需要版本号的逻辑
		这个版本号代表了数据到达doris的批次，然后是依然需要一个可见数据版本的逻辑
		整体事务提交逻辑可以得到简化，只需要一次commit即可

	数据格式转换与持久化
		核心权衡点在于写入性能与查询性能之间做权衡
		最佳实践是可以做成，用户可调节
		1 用户要求写入高吞吐，但是查询性能要求不高，那么甚至可以省略导入时的排序，直接落盘，查询时排序
		2 用户要求写入高吞吐，且查询性能要求也很高，那么写入时可以做更多排序，查询时堆更多资源
		如果要实现可权衡这个东西，核心依赖的功能就是弹性

		导入主要做的事情是，做一些预聚合操作，分桶，排序

		
		离线数据写入
			比较简单的实现，可以新起一些be，包括协调者和接收者节点
				协调者节点负责读取数据和分桶
				接收者节点负责聚合和数据格式转换
				这里的可选项是写本地存储还是写远程

			这些be其实可以作为临时的节点，用完即释放

		实时数据写入
			这些其实可以作为常驻的be进程，持续接收数据
			关于数据落盘
				这里的核心难点是写本地还是写远程存储
				如果要保证实时场景性能不下降，可能得先写本地，然后再持久化到远程存储
				这里有多套技术选型
				1 最佳的实时性，类似druid的处理方式，最近写入的数据落本地（可以是内存也可以是磁盘），持久化交给kafka
					在本地数据未写入远程存储之前，节点如果宕机都可以从kafka恢复
				2 相对较差的实时性，写本地缓存1份，写远程2份后，commit事务

			这个如果做成拓扑的结构，其实就无限接近flink了
		
		这里可以提出的一个问题是，当文件系统是一个大云盘的时候，分桶是否还是必须的？
			分桶的主要目的是通过对数据裁剪加速查询
				分桶的代价是导入流程需要多一步计算，且这个过程是无法批量处理的，对于导入性能其实是有影响的
			这个逻辑成立的前提是数据和机器是绑定的
			如果数据和机器不绑定，那么加速的手段其实就很多了，因为查询资源是可以弹性的

## 查询
	离线场景亚秒级的ap查询
		离线导入完成之后，数据预加载到本地即可

	实时查询
		如何保证查询性能不下降？
			保证本地性

		查最近
			查本地

		查历史
			历史的数据预加载到机器上
			保证查询的本地性

	adhoc
		其实目前doris的架构是可以直接跑adhoc查询的，但是由于资源隔离做的不行，稳定性比较差


## fe的元数据管理
	理想情况是sharenothing的
	需要对分布式一致性算法做一个调研

## 数据balance
	1 数据修复（需要）
	2 数据分布的平衡（需要）
		查询节点宕机恢复

		导入节点宕机恢复

## compaction
	弹性与隔离

	主要是针对持久化到远程存储的数据
	和原有逻辑比较类似，区别是可以多台be节点同时compaction一个tablet的数据

## 其他后台进程

垃圾回收
	不受什么影响

无效数据清理
	rowset
	tablet

	没有太大的影响


## 数据模型

## doris需要新增的能力 

1 doris可以动态起停be

## 存储层技术选型

存储层技术指标要求

可用性
	原来是数据分布在多个机器，单个机器挂了其实影响不大
	但是现在是数据分布在一个系统，这个系统必须是可扩展的，不能有单点设计

块存储 or HDFS?

## 如何实现弹性?

技术选型

如何与现有doris的逻辑耦合

## 最终长什么样?

# 存算分离的代价？

