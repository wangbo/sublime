# 核心目标
优化混合下的效率，混合负载主要指的是读和写

# 主要思路

1 了解设计空间，也就是权衡点，不同场景的不同解决方案
2 引入描述访问模式的频率模型；引入代价模型;
3 考虑鲁棒性

感觉就是通过分析查询模式，根据代价进行的动态优化，同时保证程序的稳定性

# 列存布局设计

所谓更新和global buffer有啥关系

列存设计的权衡点
	数据组织方式
		写入顺序
		排序
		分区

	更新策略
		in-place
		out-of-place
		hybird

	Buffering
		none
		global
		per-partition

水平分区和垂直分区
	这个没看懂

分区个数可调节来平衡读写代价
	这里有个重要的概念，所谓的分区是没有范围重叠的分区

	感觉上这里分区的概念更像是要做范围裁剪

	分区的代价
		分区越多，写代价越高，但是读代价越低
		反之亦然

	分区的类型
		分区较多，适用于读场景，对于选择性好的列，因为只需要读部分数据
		分区较少，适合更新插入删除的场景 （这个其实没太理解，分区多少和更新的关系）
		equi-width分区，不适用于访问有热点的分区（那感觉是不是通过修改并发也可以）
		narrow分区，点查和范围查比较合适

## Ghost Values
	对于更新，插入，删除操作来说，如果不要求数据是连续的话，那么移动数据的移动操作是可以省去的
	引入ghost value主要是通过降低写入时的代价，但是需要额外的空间

## 工作负载驱动决策
	范围分区和ghost value使得系统可以实现可调节的性能

	通过调节分区数，平衡读写代价
	通过增加buffer空间，可以降低写代价，但是读代价会增加；（这个应该主要是针对更新场景说的）

	通过代价模型，进行决策，找出最佳的方案

# 访问分区字段

	点查
	范围查询
		对于分区排过序且没有范围覆盖的来说，这个查找流程没啥好说的

	insert

		1 先找到该值对应的分区
		2 在最后一个分区的结尾加一个空的slot
		3 从最后一个分区开始，移动当前分区的第一个元素到下一个分区的头部
		4 这样目标分区的结尾相当于多了一个空的slot
		5 把要插入的值写入目标分区结尾


		他这个insert感觉更像是原地插入, doris目前是追加的应该
		其次我感觉这里分区的概念更像是一个连续数组内的多个区域，不是传统理解上的分区概念
		因为如果是按文件划分的话，应该直接追加到文件结尾就行了
		（应该是因为这主要是针对主内存数据库优化的）

	delete
		和insert比较类似，删除指定分区指定位置的值，然后把分区末尾的数值向前移动
		最后在最后一个分区的末尾会哟一个空的slot

	update
		delete +  insert

	这不会是面向内存数据库的设计吧

# 探索数据集，分区方案和工作负载的关系

## 分区方案
		最小单位是个block
		分区可以有如下方式
		1 每个分区有相等的block数
		2 每个分区的block数不等

## 频率模型
		定义直方图，block被哪个操作访问

		定义操作
			pq,点查询
			rs，范围查询的起始
			re，范围查询的结束
			sc，全block扫描
			de，为每个block定义delete操作
			in,insert
			udf,udb 更新相关
			utf，ufb

		更新直方图
			根据对block的访问更新，对定义的操作进行更新，比如做+1

		如何使用这个模型
			对所有block有所分区的访问操作进行统计，可以分为10种，主要是统计访问次数
			访问频率结合分区个数，可以得出一个代价模型

			这个更像是一种滞后的调节



## 代价函数(如何计算代价)
		对于主内存数据库来说，分区的边界是逻辑上的，因此可以在运行时动态调整

		先说明分区边界的意义，应该是可以直接用于过滤数据的
		一个分区包含多个block

		这里的关键是，如何把代价问题转换成数学问题

		定义数据的读取方式
			RR，随机读
			RW，随机写
			SR，顺序读
			SW，顺序写
		
		范围查询模型

		定义代价函数的核心逻辑
			在本文中，所谓分区其实就是范围索引，索引的范围越细，无效读就越少
			
			范围起始读的代价
					(3,1)  p0  (5,4)  p1  (7,8)  p2
					  1			 2			3

					rs2 · RR + rs2 · SR · ((1 − p1 ) + (1 − p1)(1− p0))

					计算范围读第三个block的代价（此时假定范围读的起始是在block3中）
					
					从本文的角度看，这个公式如何理解
						rs2 · RR，代表了读最左侧第一个block的代价，就是一个随机读的代价，不管目标的block和距离起始block差了多少，这个第一次读的代价是没法省的
						右边的公式则是和边界有关
							p1=0，代表边界不存在，那么就要多一次顺序读
							p0和p1都不存在，那么就要多两次顺序




				中间全量读的代价和范围读结尾的代价计算比较类似

				总代价是，
					范围起始读的代价 + 中间全量读的代价 + 范围读结尾的代价

				而且当前的假设认为，范围的起始读和范围的结尾读都是随机读，中间的block由于要读全量，所以是顺序读
				这应该是因为，一个block内是二分查找的

				这里可以提出两个问题

				1 有了范围查询的总代价之后，可以如何使用?(或者说这个总代价如何理解)
					rs这些访问频率是现实实际存在的，不可变的
					但是1-p这些分区边界是可以变动的
					所以用法是，运行一段时间之后，rs的值有了，公式中rs的值不变，通过调节p的值，来计算出更低的代价，新的p的值就是边界

				2 总代价计算公式到底如何理解?
					边界值其实就是个bool，p存在就为1，不存在就为0

		    点查询
		    	cost pq(pqi)=pqi·RR+ pqi ·SR·(fwd read(i)+bck read(i))
		    	固定的一次随机读的代价 + 向前读和向后读的次数的代价

		    insert
		    delete
		    update

		    Overall Workload Cost


# 代价模型验证
	
	分区越大（索引粒度越大），查询延迟越高，这听起来像是废话

# 优化列存布局(或者)
	我们首先定义一个sla，其实就是定义了一个最大的代价，当前计算出的代价不能超过最大代价
	SLA可以理解为是性能的约束，其实这里有两个问题
		1 为啥要有性能上界，为什么不尝试超出最小的呢？看起来追求最佳是一种追求，但是考虑实际的业务场景，似乎确实定一个最大值是比较合理的
		2 这里的sla到底是个逻辑上的概念，还是直接对应到用户感知的概念呢？合理的做法是啥样的

	更新延迟约束
	读延迟约束
		RR+SR·MPS = readSLA ⇒ MPS = (readSLA −RR) / SR
		MPS是最大分区数，这个公式可以理解为，给定一个最大性能的上界，我可以算出最大分区数

			



