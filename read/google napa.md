# Napa: Powering Scalable Data Warehousing with Robust Query Performance at Google

## 问题与背景
* 主要面向OLAP场景
* 数据量是行星尺度的大
* 亚秒级的查询响应
* 支持实时场景下的更新
* 用于替换MESSA
* 全球级别多数据中心的数据一致性保证(对于谷歌来说有很多现成的组件可以用，应该算是基本操作)

### 系统特色
* 查询性能的鲁棒性；依照文章中的说法，主要是通过物化视图实现，物化视图的覆盖度越高越容易做到；单纯依赖提升计算能力是比较困难的
* 灵活性；用户可以在查询性能，代价和数据新鲜度（可以理解为实时场景的导入延迟）之间做权衡
* 更新场景下的高吞吐摄入，主要通过异步延迟构建物化视图实现，当然物化视图之间是要保证一致性的

## 设计约束
* 在谷歌用户对系统的要求可以概括为三个方面，查询性能，实时数据延迟以及代价
* 由于谷歌的用户众多，对这三个方面的要求存在差异，比如某个用户对延迟敏感但是代价和性能不敏感
* 这个有点类似CAP理论，三个方面同时都要求最佳应该是做不到，只能是做取舍；主要特别注意的是，这里说的做取舍是指，系统开发者把做权衡的开关做好，用户根据需求自行进行取舍
* 举个例子
** 对于数据新鲜度不敏感的用户，可以选择把导入和物化视图的构建进行耦合
** 对于数据新鲜度很敏感的用户，可以选择延迟构建物化视图
** 如果一个用户既要求数据很新鲜，又要求查询延迟很低很稳定，那么可以做的是投入更多资源来做物化视图的构建和compaction，但也只能使得结果接近理想情况，无法达到最佳；因为以现有的技术实现，低查询延迟和低导入延迟本身就是矛盾的；

## 架构设计与实现
结合上文的设计约束，可以把系统拆成如下三个组件
* 数据导入系统
** 把增量写的数据（delta数据）提交到表中，满足最基本的持久化要求即可

* 存储系统
**把delta数据更新到物化视图中；也负责做compaction工作

* 查询服务

**响应客户端的sql查询请求，会做一些读时的delta merge操作;

### 如何为客户端提供灵活性
* 用户通常理解的查询性能，数据新鲜度以及代价可以直接转换成数据库配置，比如物化视图的个数，各种离线task的数量以及以及读数据时的delta文件的数量
* Queryable Timestamp(QT)，主要指明了数据新鲜度（now - QT），关于QT的一些基本规则如下
** 只有时间戳小于QT的数据可以查询的
** QT可以增长的条件是，给定数量的物化视图构建完成并且delta文件的个数不超过配置
** QT稳定增长可以认为在当前的数据库配置下（比如n个物化视图，m个delta），用户对查询的各项要求是可以满足的；
* 举个例子
** 某个用户希望数据的新鲜度和查询性能都很好，同时可以付出更高的代价；
** 这意味这个表需要维护很多的物化视图以及保证查询时有很少的delta文件同时满足时，QT的值才可以增长
** 对于NAPA来说，需要启动大量的compaction以及构建物化视图的Task才能同时保证查询时的性能以及鲁棒性

### 数据的可用性
* 支持全球多数据中心的数据一致性
* 这里的创新之处，先保证单数据中心内的数据一致性，完成所谓的数据操作；多个数据中心之间的数据一致性是批量的异步操作完成的

### 来一张架构图
* 用的是谷歌自己的分布式文件系统
* 用Spanner提供严格的事务语义（类似Doris的FE）
* 使用F1 Query完成查询服务以及视图创建的服务，F1 Query同时支持流式处理和批处理的场景

## 一些模块细节

### 数据导入模块
* 和视图维护模块是解耦的，主要保证的是数据的持久化
* 提供了资源控制的按钮，这里的资源控制主要说的是对接收数据，执行导入聚合以及数据复制的task数目进行动态调控的能力

### 关于QT
* 其实就是用于衡量数据导入延迟的
* NAPA认为查询时open和merge的delta问你件数量是非常影响查询性能的，如果想提升查询的性能，那么应该尽可能减少查询时的dela文件的数量
* 因此会有一个自动的模块根据表的查询负载对delta文件的数量进行限制，查询负载越高的场景，预期的delta文件数是越少的
（这里有几个问题，查询负载如何衡量，如何动态调节）
* NAPA中QT的保证是非常依赖compaction和物化视图的
* QT也可以用于指明数据一致性，包括本地副本，机房内，跨机房
* 对应于doris中version的概念，一个version只commit但是不publish是不可见的；只有publish之后才是可见的

### 维护大规模的视图
* 用F1 Query完成compaction和视图的维护
* 会对数据倾斜的情况进行检测并优化
* 只能检测长尾的物化视图；为了保证物化视图的一致性，物化视图的更新速度主要会受制于更新最慢的那个，NAPA会对这种情况进行检测并尝试调度更多资源对这种情况进行解决

#### 视图的查询优化挑战
* 充分利用数据属性进行处理
* 利用key的分布
** 物化视图和base表的key列顺序完全相同，那么在构建物化视图的时候是可以避免排序操作的
** key列部分顺序相同，那么可以只根据不同的key进行分组内的排序
** key列顺序完全不同，那么就只能是shuffle了
* 对于数据属性的利用
** 上卷后基数低的可以尝试先聚合后排序
** 对于上卷后和原表差不多的，排序和merge的效率比较重要

这一节感觉都是比较朴实无华的细节优化，没啥好说的

#### 关于compaction
* compaction对于高频导入的数据是很昂贵的操作，并且会影响数据的新鲜度
* I/O Prefetch，这个没看懂

## 鲁棒查询性能
* 谷歌的内部场景要求
** 严格的亚秒级响应要求
* 影响因素
** 长尾(感觉上是某个并发会比较慢)
** 子系统服务的稳定性

### 优化思路
* 减少数组读取时关键路径上的数据量
** 视图优先于base表
** 谓词和聚合下推

### 最小化顺序IO的数量
* 元数据纯内存
* 离线Prefetch，数据刚摄入，在可读之前，对于高频查询的表会对数据进行预加载
* Online Prefetch，查询运行时，生成一个只读的Executor，提前加载磁盘数据

### 合并Small IO
* 在查询时Napa会积极地做很多并行化的操作，包括delta粒度的并行IO调用以及字段粒度的（这里说的并行化IO调用每太理解，是并行读磁盘？）
* 并行化的代价，长尾延迟
* 解决长尾主要有两个思路，一个是限制查询时的delta数，另一个是合并小IO
* 合并小IO的两种技术
** 跨delta的延迟merge（这个我感觉就不是很通用的优化技术，没啥好说的）
** size-based disk layout；对于很多小的delta文件，可以一次IO全读出来，参考PAX layout [2]

我觉得这节的参考价值是比较大的，首先声明了长尾问题对于查询鲁棒性的影响
然后指出磁盘IO的访问的长尾效应对整个查询是有影响的
最后给出的优化方案比较有参考价值的是多个小的delta文件可以通过一次IO完成，从而降低磁盘长尾的影响
另外可以补充记录的一条原则是，引入并行时一定得考虑长尾问题

### 容忍长尾和失败
* NAPA采用容忍而不是消除长尾的原则，因为尝试消除长尾
* 对于非流式，会发起两次调用，取最快的那个
* 对于流式调用，会检查执行进度是否会符合预期，如果不符合预期那么再发起一个新的请求，这个有点类似于推测执行

## PRODUCTION METRICS INSIGHTS
* by decoupling ingesting, view maintenance, and query execution; Napa can mitigate the impact of infrastructure and workload changes on query performance
* 查询性能相关指标，视图个数与查询延迟的关系，delta个数与查询延迟的关系
* 处理基础设施的问题，napa可以在导入负载变化以及其他基础设施挂掉的时候，保证客户端的查询性能
* 客户端灵活性

# 总结
* 整体架构，导入，视图维护以及查询组件的解耦，表达上有新意，但其实是存算分离的必然结果；不过对于doris完全耦合到的设计来说，是有借鉴意义的
* 对于查询鲁棒性的问题，从架构设计角度给出了可行的解决方案，那就是通过添加物化视图+QT的逻辑来保证
* 最大的亮点是用户灵活性，从数据新鲜度，查询性能以及导入延迟三个方面进行抽象，给用户进行选择的权利，这会带来以下好处
** 支持用户的个性化配置；当把权衡的权利交给用户之后，形成一个效果是数据库中的每份数据，都有自己最合理的处理方式，整个集群的资源会根据场景进行自适应，从而获得最合理的分配
（以Doris的compaction为例说明，当一个be节点有几十万个tablet的时候，compaction线程的数量级应该在几十，那么这些tablet哪些是实时场景的tablet，哪些是离线场景的tablet，哪些sla任务的tablet，哪些是非sla任务的tablet，先有的compaction逻辑是不会考虑这些的，而是只会看到tablet视角的信息，那么很显然这种compaction选择算法是不太能适应比较复杂的业务场景的；但如何能够支持用户自己进行配置，那么集群的资源应该是会被得到最合理的利用）
** 明确了用户能力边界和系统的能力边界，用户的需要了解自己的业务场景，根据业务场景确认权衡点；而引擎则是需要能够支持用户做出权衡
（可以举一个实际场景的例子）
* 存算分离的时候可以完美支持弹性设计，当系统拥有弹性的能力时，能够提升在输入负载变化时系统的稳定性
* 要能够支持用户的灵活性，需要系统具备哪些能力？弹性；一个输入接口，支持把用户理解的权衡点转成系统配置参数
* 解耦设计的优点(待补充一些)

# 对比Doris现状

## 从用户角度出发梳理现有的问题与最佳实践

### 美团业务场查询景现状
1 秒级的查询延迟要求
2 即席查询的长查询要求（多表join关联）
3 用于ETL生产的长查询
4 单集群支持多种混合负载的情况
5 弹性要求（较少，仅限住宿直播和外卖部分场景）

### 稳定性

系统稳定性是什么？
1 外界发生的各种变化（用户输入变化/硬件宕机），不至于对系统的状态发生显著的影响
2 系统受到某种干扰而偏离正常状态，当干扰消除能偶恢复其正常状态

系统的稳定性受什么影响？
1 BUG，只能由系统RD解决
2 用户输入负载变化（查询/导入），最佳实践是用户可以自行解决，但现状是主要靠堆人力
3 硬件宕机，只能由系统SRE处理
以上只列举了影响因素，但是具体实际发生的占比待统计，总之目前很缺用户使用场景的数据

NAPA的用户灵活性设计其实是可以解决用户负载变化导致的，比如当查询延迟增加时，用户可以看下是否是rollup构建过慢以及查询时的的delta过多
如果是导入流量突增导致的，那么可以尝试调大compaction以及加rollup的task数目的，从而使得查询延迟恢复正常
如果可用的delta数目以及rollup数目没有变化，那么说明单纯是查询负载变化，那么可以尝试通过按钮增加查询资源
总之，一切由用户输入负载导致的稳定性问题，理论上都是可以用户自助解决，而不需要RD介入，从而缩短用户解决问题的时间，也降低了RD的运维成本
RD需要做的是，让系统具备弹性，提供监控指标，提供权衡的接口即可

Doris目前的架构设计是无法解决用户输入负载导致的稳定性问题的，目前只能依靠堆人力去解决，主要由于目前Doris主要采用紧耦合的设计
1 一个是混合负载下稳定性很难保证，但进程内部要同时支持多种负载的查询，多种离线Task（compaction，alter job），相互影响是很正常的事情，稳定性没法保证是客观事实
2 由于目前做不到弹性，流量变化的情况下，基本上用户只能干瞪眼，RD能做的也就是解释下原因，然后大家一起看着系统处于不稳定的状态而毫无办法


### 易用性
比较差
其中一个点是，目前用户对引擎的能力边界是没有认知的，这导致当系统出现稳定性问题时，其实不太能分得清到底是自己的问题还是系统的问题
而NAPA的这种用户灵活性设计是可以帮助用户知道使用一个引擎时，自己要做什么，系统能提供的是什么
并且如果是用户自己的问题，可以根据系统提供的接口进行快速调整

### 性能
我觉得还好，目前大部分场景可以满足


综上，Doris现在纯耦合的设计其实是没法完全满足美团现有业务场景下的稳定性要求的，现有的稳定性维护纯靠堆人力运维
最佳实践其实就是为NAPA引入用户灵活性的概念，以此为核心对Doris的架构进行重新设计，可以提升整体系统的稳定性和易用性
降低用户使用成本和运维成本



## 最佳实践是否适合美团
考虑因素，业务规模（现在和未来）
运维成本

# 扩展阅读
* interesting orderings[28]
** 如何利用数据的属性优化排序
* 关于排序和merge的文献[15][22][23]

