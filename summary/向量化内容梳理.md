# 概念
## ```data locality```与```predictable branch```是什么？
如何衡量，如何观察，如何验证



# 论文关键点总结
## Efficiently Compiling Efficient Query Plans for Modern Hardware

### 论文中关键结论概览
	* 虚函数调用的影响
		* 比普通函数调用开销要大
		* 降级分支预测
		* 代码本地性较差。一次只产生一个tuple，中间会有其他代码调用，比如解压操作
	* 流水线
		* operator之间传递数据不需要拷贝以及物化数据
		* 一次调用产生超过一个tuple，流水线就会被打破，因为这个tuple必须物化到某个地方
		* 打破流水线会带来更多的内存带宽的消耗
	* tuple与batch
		* tuple不同的函数调用之间传递，这会导致数据从寄存器从evict
		* 面向批处理的方式受函数调用的影响较小，但是由于需要物化超出寄存器大小的tuple，因此会打破流水线
		* 综上，所以感觉不管是函数调用还是batch都不是最佳方案，codegen才是王道？
	* when calling an external function all registers have to be spilled to memory
	* Materializing attributes in memory is a deliberate(值得商榷) decision, similar to spooling tuples to disk.
	 a code point of view materialization is a very complex step that should be avoided if possible
	* 在tight loop中进行tuple的遍历，可以利用内存Prefetch和精确的分支预测
	* 只要能够将block都保存在寄存器中，那么一次处理多个tuple就是个不错的注意

### 迭代器模型的主要问题
	* 优势与劣势
		* 擅长处理IO密集型的场景
		* 不擅长处理CPU密集型的场景
	* CPU不够友好的原因
	 	* 缺乏data locality
		* 大量的虚函数调用
			* 虚函数调用开销要远远高于普通的函数调用
			* 降级分支预测
		* 缺乏code locality
			* 以scan一张压缩表为例，从一个压缩的流中读取数据时，中间需要通过函数调用跳转到解压的逻辑
				(这个问题其实可以通过一次性解压全部数据，然后只迭代解压后的数据)
	* 综上，迭代器模型的虚函数调用开销是对cpu不够友好的主要原因


### 面向批处理方案的主要问题
	* 批处理方式的优势
		* 可以有效分摊函数调用的开销
		* 可以利用向量化的指令
	* 批处理方式带来的问题
		* 打破了迭代器模型的主要优势，```pipeline data```
	* ```pipeline data``
		* operator可以把数据直接传递给parent operator不需要额外的数据拷贝与物化
		* ```当一次调用产生多个tuple时，这种pipeline就会被打破，数据就需要被物化到某个地方```
		* 打破pipeline的主要问题是会产生额外的内存带宽
		* 据论文描述，手写代码甚至也要远远比最快的向量化要更快

### 问题总结
迭代器模型函数调用开销很高->批处理可以解决函数调用开销的问题，但是会带来额外的物化开销，打破pipeline

### 本文提出的核心解决方案
	* 以数据为中心进行数据的处理，尽可能的把数据保存在cpu寄存器中持续较长的时间，通过模糊operator的边界来达到这一目标
	* 使用push代替pull，这会带来更好的code和data locality
	* 使用llvm把查询编译成机器码

### pipeline breaker
	* 目的
		* 最大化代码本地性和数据本地性
	* 定义
		* 会把接收到的tuple放到寄存器外面
	* full pipeline breaker
		* 在继续处理之前，物化所有输入的tuple
	* 更加宽泛一点的定义
		* spilling data to memory as a pipeline breaker

### 编译模型produce/consume
	* 基本思路
		* 以pipeliner breaker为边界，将查询计划拆分成不同的fragment
		* 每个fragment内部都是完全的流水线处理
		* tuple可以一直保存在寄存器中，除非是要物化或者写入主存
		*（从这个视角来看的话，一个tuple在当前算子内部或者多个算子内部，最好只物化一次，需要避免的情况是反复的物化）
	* 可以值得探究的点是，可以看下论文附录里说的最佳的手写代码具体是长什么样的？

### CodeGen
	* 方案1：动态编译成C++的代码
		* C++的编译器实在是太慢了
	* 方案2：动态编译成汇编代码
		* 汇编代码实在是太难写了
	* 方案3：C++代码和汇编码混合（采用LLVM）
		* C++主要用来运行比较复杂的逻辑，驱动整个执行流
		* 当tuple需要批量处理的时候，可以采用汇编码进行处理

### 很复杂的operator的codegen的问题
	* 把一个复杂的查询编译成一个函数是不现实的
		* C++代码和LLVM代码会相互调用
		* 代码膨胀会比较严重
	* 比较热的代码路径，最好不要跨函数边界

### 高级并行技术
	* 每次处理多个tuple是个很不错的主意，只要能够将多个tuple保存在寄存器中
		* 可以利用simd指令[15]
		* delay branching[12][14]
	* 多核处理[10][3]
		* 对输入的operator进行分区，然后对所有分区的结果进行merge

### 一些工具
	* callgrind tool of valgrind 3.6.0
		* 可以观测分支和cache的影响


